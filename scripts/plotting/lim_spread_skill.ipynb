{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spread skill and optimal initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from hyblim.data import preproc, eof\n",
    "from hyblim.utils import metric, enso\n",
    "\n",
    "plt.style.use(\"../../paper.mplstyle\")\n",
    "\n",
    "def get_model_specs_by_name(experiments, exp_name):\n",
    "    for exp in experiments:\n",
    "        if exp['name'] == exp_name:\n",
    "            return exp \n",
    "    return None\n",
    "\n",
    "# Load list of experiments\n",
    "with open(\"experiments.yaml\", \"r\") as f:\n",
    "    experiments = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapaths = {}\n",
    "datapaths['ssta'] = \"../../data/cesm2-picontrol/b.e21.B1850.f09_g17.CMIP6-piControl.001.pop.h.ssta_lat-31_33_lon130_290_gr1.0.nc\"\n",
    "datapaths['ssha'] = \"../../data/cesm2-picontrol/b.e21.B1850.f09_g17.CMIP6-piControl.001.pop.h.ssha_lat-31_33_lon130_290_gr1.0.nc\"\n",
    "\n",
    "da_arr, normalizer = [], {}\n",
    "for var, path in datapaths.items():\n",
    "    da = xr.open_dataset(path)[var]\n",
    "    # Normalize data \n",
    "    normalizer_var = preproc.Normalizer()\n",
    "    da = normalizer_var.fit_transform(da)\n",
    "    # Store normalizer as an attribute in the Dataarray for the inverse transformation\n",
    "    da.attrs = normalizer_var.to_dict()\n",
    "    da_arr.append(da)\n",
    "    normalizer[var] = normalizer_var\n",
    "\n",
    "ds = xr.merge(da_arr)\n",
    "\n",
    "# Apply land sea mask\n",
    "lsm = xr.open_dataset(\"../../data/land_sea_mask_common.nc\")['lsm']\n",
    "ds = ds.where(lsm!=1, other=np.nan)\n",
    "\n",
    "nino_indices = enso.get_nino_indices(ds['ssta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA\n",
    "n_eof = [20,10]\n",
    "eofa_lst = []\n",
    "for i, var in enumerate(ds.data_vars):\n",
    "    print(f\"Create EOF of {var}!\")\n",
    "    n_components = n_eof[i] if isinstance(n_eof, list) else n_eof \n",
    "    eofa = eof.EmpiricalOrthogonalFunctionAnalysis(n_components)\n",
    "    eofa.fit(\n",
    "        ds[var].isel(time=slice(None, int(0.8*len(ds['time']))))\n",
    "    )\n",
    "    eofa_lst.append(eofa)\n",
    "combined_eof = eof.CombinedEOF(eofa_lst, vars=list(ds.data_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in training and test data\n",
    "train_period = (0, int(0.8*len(ds['time'])))\n",
    "val_period = (int(0.8*len(ds['time'])), int(0.9*len(ds['time'])))\n",
    "test_period = ( int(0.9*len(ds['time'])), len(ds['time']) ) \n",
    "\n",
    "data = dict(\n",
    "    train = combined_eof.transform(ds.isel(time=slice(*train_period))),\n",
    "    val = combined_eof.transform(ds.isel(time=slice(*val_period))),\n",
    "    test = combined_eof.transform(ds.isel(time=slice(*test_period))),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get nino hindcast of LIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasplit = 'test'\n",
    "\n",
    "nino_scores, nino_scores_month = {}, {}\n",
    "exp = get_model_specs_by_name(experiments, \"LIM\")\n",
    "nino_frcst = xr.open_dataset(exp['paths'][0] + '/metrics/nino_frcst_test.nc').transpose('time', 'member', 'lag')\n",
    "nino_target = xr.open_dataset(exp['paths'][0] + '/metrics/nino_target_test.nc').transpose('time','lag')\n",
    "nino_scores, nino_scores_month = metric.time_series_score(nino_frcst, nino_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spread skill ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_skill = nino_scores['spread_skill']['nino4']\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,3))\n",
    "ax.plot(spread_skill.lag, spread_skill.data, 'o-', color='darkblue', label='LIM')\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.axhline(1.0, color='gray', linestyle='--')\n",
    "ax.set_xlabel('Lead time (months)')\n",
    "ax.set_ylabel('Spread/Skill')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_arr = [6, 12]\n",
    "\n",
    "nrows = len(lag_arr)\n",
    "fig, axs = plt.subplots(1, nrows, figsize=(5*nrows, 3))\n",
    "for i, lag in enumerate(lag_arr):\n",
    "    ax = axs[i]\n",
    "    spread = nino_frcst['nino4'].sel(lag=lag).std('member')\n",
    "    skill = np.abs(nino_frcst['nino4'].sel(lag=lag).mean('member') - nino_target['nino4'].sel(lag=lag))\n",
    "\n",
    "    ax.plot(spread.data, skill.data, '.', markersize=1, color='grey', label=rf\"$\\tau$={lag}\")\n",
    "    sns.kdeplot(x=spread.data, y=skill.data, ax=ax,\n",
    "            alpha=0.8, fill=True, cmap='Blues')\n",
    "\n",
    "    ax.set_xlabel('Spread')\n",
    "    ax.set_ylabel('Skill (RMSE)')\n",
    "    ax.set_ylim(0, 2.2)\n",
    "    ax.legend(loc='upper right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load opitimal initial patterns and their evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_init_pc = xr.open_dataarray(\"../../models/lim/cslim_ssta-ssha/metrics/optimal_init_pc.nc\")\n",
    "optimal_evolved_pc = xr.open_dataarray(\"../../models/lim/cslim_ssta-ssha/metrics/optimal_evolved_pc.nc\")\n",
    "optimal_init_map = xr.open_dataset(\"../../models/lim/cslim_ssta-ssha/metrics/optimal_init_map.nc\")\n",
    "optimal_evolved_map = xr.open_dataset(\"../../models/lim/cslim_ssta-ssha/metrics/optimal_evolved_map.nc\")\n",
    "optimal_init_map = -1* optimal_init_map / optimal_init_map.std()\n",
    "optimal_evolved_map = -1* optimal_evolved_map / optimal_evolved_map.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_month = 5\n",
    "lag = 9\n",
    "\n",
    "\n",
    "# Project optimal initial and evolved patterns onto the data \n",
    "idx_init_times = np.argwhere(\n",
    "    (data['test']['time'].dt.month.values == init_month)\n",
    ").flatten()[:-lag]\n",
    "z_init = data['test'].isel(time=idx_init_times)\n",
    "\n",
    "opt_init = optimal_init_pc.sel(month=init_month, lag=lag)\n",
    "opt_evolved = optimal_evolved_pc.sel(month=init_month, lag=lag)\n",
    "\n",
    "proj_data_opt_init = xr.DataArray(data=opt_init.data @ z_init.data.T, \n",
    "                                  coords=dict(time=z_init['time'].data))\n",
    "proj_data_opt_init = np.abs(proj_data_opt_init)\n",
    "\n",
    "target_dates = np.intersect1d(\n",
    "    preproc.add_to_cftime(proj_data_opt_init.time.data, lag), nino_frcst.time.data\n",
    ")\n",
    "spread = nino_frcst['nino4'].sel(lag=lag, time=target_dates).std('member')\n",
    "skill = np.abs(\n",
    "    nino_frcst['nino4'].sel(lag=lag, time=target_dates).mean('member')\n",
    "    - nino_target['nino4'].sel(lag=lag, time=target_dates)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(5,3))\n",
    "im = ax.scatter(spread.data, skill.data, c=proj_data_opt_init.data[:-1], cmap='viridis_r')\n",
    "ax.set_xlabel('Spread')\n",
    "ax.set_ylabel('Skill (RMSE)')\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(im, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "percentiles = [\n",
    "    [0, 20],\n",
    "    [20, 40],\n",
    "    [40, 60],\n",
    "    [60, 80],\n",
    "    [80, 100],\n",
    "]\n",
    "lag_arr = [1, 3, 6, 12, 18, 24]\n",
    "\n",
    "\n",
    "spread, skill = [], []\n",
    "for lag in lag_arr:\n",
    "    spread_lag, skill_lag = [], []\n",
    "    for init_month in range(1, 13):\n",
    "        # Project optimal initial and evolved patterns onto the data \n",
    "        idx_init_times = np.argwhere(\n",
    "            (data['test']['time'].dt.month.values == init_month)\n",
    "        ).flatten()[:-lag]\n",
    "        z_init = data['test'].isel(time=idx_init_times)\n",
    "\n",
    "        opt_init = optimal_init_pc.sel(month=init_month, lag=lag)\n",
    "        opt_evolved = optimal_evolved_pc.sel(month=init_month, lag=lag)\n",
    "\n",
    "        proj_data_opt_init = xr.DataArray(data=opt_init.data @ z_init.data.T, \n",
    "                                          coords=dict(time=z_init['time'].data))\n",
    "        proj_data_opt_init = np.abs(proj_data_opt_init)\n",
    "\n",
    "        spread_month, skill_month = [], []\n",
    "        for (pmin, pmax) in percentiles:\n",
    "            # Select percentilse\n",
    "            idx_init_dates = np.where(\n",
    "                (proj_data_opt_init.data >= np.percentile(proj_data_opt_init, pmin))\n",
    "                & (proj_data_opt_init.data <= np.percentile(proj_data_opt_init, pmax))\n",
    "            )[0]\n",
    "            init_dates = proj_data_opt_init['time'].data[idx_init_dates]\n",
    "            target_dates = np.intersect1d(\n",
    "                preproc.add_to_cftime(init_dates, lag), nino_frcst.time.data\n",
    "            )\n",
    "\n",
    "            print(f\"Number of initial dates: {len(init_dates)}\")\n",
    "\n",
    "\n",
    "            spread_month.append(\n",
    "                nino_frcst['nino4'].sel(lag=lag, time=target_dates).std('member').mean('time')\n",
    "            )\n",
    "            skill_month.append(\n",
    "                np.sqrt(np.square(nino_frcst['nino4'].sel(lag=lag, time=target_dates).mean('member')\n",
    "                - nino_target['nino4'].sel(lag=lag, time=target_dates, method='nearest')).mean('time'))\n",
    "            )\n",
    "        spread_lag.append(\n",
    "            xr.concat(spread_month, dim=pd.Index([pmin for pmin, pmax in percentiles], name='percentile'))\n",
    "        )\n",
    "        skill_lag.append(\n",
    "            xr.concat(skill_month, dim=pd.Index([pmin for pmin, pmax in percentiles], name='percentile'))\n",
    "        )\n",
    "    \n",
    "    spread.append(\n",
    "        xr.concat(spread_lag, dim=pd.Index(range(1, 13), name='month'))\n",
    "    )\n",
    "    skill.append(\n",
    "        xr.concat(skill_lag, dim=pd.Index(range(1, 13), name='month'))\n",
    "    )\n",
    "spread = xr.concat(spread, dim=pd.Index([1, 3, 6, 12, 18, 24], name='lag'))\n",
    "skill = xr.concat(skill, dim=pd.Index([1, 3, 6, 12, 18, 24], name='lag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(lag_arr)\n",
    "month = 5\n",
    "\n",
    "fig, axs = plt.subplots(nrows, 1, figsize=(5, 3*nrows), sharex=True)\n",
    "for i, lag in enumerate(lag_arr):\n",
    "    ax = axs[i]\n",
    "    ax.plot(spread.percentile, spread.sel(lag=lag).mean('month').data, 'o-', label='Spread')\n",
    "    ax.plot(skill.percentile, skill.sel(lag=lag).mean('month').data, 'o-', label='Skill')\n",
    "    ax.set_xlabel('Percentile')\n",
    "    ax.set_ylabel('RMSE')\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Lead time: {lag} months\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
