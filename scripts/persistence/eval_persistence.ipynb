{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistent forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, argparse\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy as ctp\n",
    "\n",
    "import hyblim.geoplot as gpl\n",
    "from hyblim.data import eof, preproc\n",
    "from hyblim.utils import metric, eval, enso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapaths = {}\n",
    "datapaths['ssta'] = \"../../data/cesm2-picontrol/b.e21.B1850.f09_g17.CMIP6-piControl.001.pop.h.ssta_lat-31_33_lon130_290_gr1.0.nc\"\n",
    "datapaths['ssha'] = \"../../data/cesm2-picontrol/b.e21.B1850.f09_g17.CMIP6-piControl.001.pop.h.ssha_lat-31_33_lon130_290_gr1.0.nc\"\n",
    "n_eof = [20, 10]\n",
    "\n",
    "# Load data\n",
    "print(\"Load data!\", flush=True)\n",
    "normalizer = dict()\n",
    "da_arr = []\n",
    "for var, path in datapaths.items():\n",
    "    da = xr.open_dataset(path)[var]\n",
    "    # Normalize data \n",
    "    norm = preproc.Normalizer()\n",
    "    da = norm.fit_transform(da)\n",
    "    # Store normalizer as an attribute in the Dataarray for the inverse transformation\n",
    "    da.attrs = norm.to_dict()\n",
    "    da_arr.append(da)\n",
    "    normalizer[var] = norm\n",
    "\n",
    "ds = xr.merge(da_arr)\n",
    "\n",
    "# Apply land sea mask\n",
    "lsm = xr.open_dataset(\"../../data/land_sea_mask_common.nc\")['lsm']\n",
    "ds = ds.where(lsm!=1, other=np.nan)\n",
    "\n",
    "# Train, val, test split\n",
    "train_period = (0, int(0.8*len(ds['time'])))\n",
    "val_period = (int(0.8*len(ds['time'])), int(0.9*len(ds['time'])))\n",
    "test_period = (int(0.9*len(ds['time'])), len(ds['time'])) \n",
    "\n",
    "data = dict(\n",
    "    train = ds.isel(time=slice(*train_period)),\n",
    "    val = ds.isel(time=slice(*val_period)),\n",
    "    test = ds.isel(time=slice(*test_period)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistence forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasplit = 'test'\n",
    "lag_arr = [1, 3, 6, 9, 12, 15, 18, 21, 24]\n",
    "\n",
    "ds_eval = data[datasplit]\n",
    "verification_per_gridpoint, verification_per_time, nino_indices = [], [], []\n",
    "for lag in lag_arr:\n",
    "    print(f\"Compute metrics for lag {lag}\", flush=True)\n",
    "    x_target = ds_eval.isel(time=slice(lag, None))\n",
    "    x_frcst = ds_eval.isel(time=slice(None, -lag))\n",
    "    x_frcst['time'] = x_target['time']\n",
    "\n",
    "    # Unnormalize\n",
    "    for var in x_target.data_vars:\n",
    "        x_target[var] = normalizer[var].inverse_transform(x_target[var])\n",
    "        x_frcst[var] = normalizer[var].inverse_transform(x_frcst[var])\n",
    "\n",
    "    # Compute metrics per gridpoint\n",
    "    grid_verif = metric.verification_metrics_per_gridpoint(\n",
    "        x_target, x_frcst, None\n",
    "    )\n",
    "    grid_verif['lag'] = lag\n",
    "    verification_per_gridpoint.append(grid_verif)\n",
    "    \n",
    "    # Compute metrics per time\n",
    "    time_verif = metric.verification_metrics_per_time(\n",
    "        x_target, x_frcst, None\n",
    "    )\n",
    "    time_verif['lag'] = lag\n",
    "    verification_per_time.append(time_verif)\n",
    "\n",
    "    # Nino indices\n",
    "    nino_index = {\n",
    "        'target': enso.get_nino_indices(x_target['ssta']),\n",
    "        'frcst': enso.get_nino_indices(x_frcst['ssta']),\n",
    "        'lag': lag\n",
    "    }\n",
    "    nino_indices.append(nino_index)\n",
    "\n",
    "verification_per_gridpoint = metric.listofdicts_to_dictofxr(verification_per_gridpoint, dim_key='lag')\n",
    "verification_per_time = metric.listofdicts_to_dictofxr(verification_per_time, dim_key='lag')\n",
    "nino_indices = metric.listofdicts_to_dictofxr(nino_indices, dim_key='lag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to file\n",
    "print(\"Save metrics to file!\", flush=True)\n",
    "scorepath = f\"../../models/persistence/\"\n",
    "if not os.path.exists(scorepath):\n",
    "    os.makedirs(scorepath)\n",
    "\n",
    "for key, score in verification_per_gridpoint.items():\n",
    "    score.to_netcdf(scorepath + f\"/gridscore_{key}_{datasplit}.nc\")\n",
    "for key, score in verification_per_time.items():\n",
    "    score.to_netcdf(scorepath + f\"/timescore_{key}_{datasplit}.nc\")\n",
    "for key, nino_idx in nino_indices.items():\n",
    "    nino_idx.to_netcdf(scorepath + f\"/nino_{key}_{datasplit}.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "scorekey = 'cc'\n",
    "lag = 12\n",
    "vars = ['ssta', 'ssha']\n",
    "plparam  = {\n",
    "    'mse' : {'ssta': dict(cmap='plasma', vmin=0, vmax=2, eps=0.25),\n",
    "             'ssha': dict(cmap='plasma', vmin=0, vmax=150, eps=10)},\n",
    "    'rmsess' : {'ssta': dict(cmap='RdGy_r', vmin=-.9, vmax=.9, eps=0.1),\n",
    "                    'ssha': dict(cmap='RdGy_r', vmin=-.9, vmax=.9, eps=0.1)},\n",
    "    'cc' : {'ssta': dict(cmap='RdBu_r', vmin=-1.0, vmax=1.0, eps=0.1, centercolor=\"#FFFFFF\"),\n",
    "            'ssha': dict(cmap='RdBu_r', vmin=-1.0, vmax=1.0, eps=0.1, centercolor=\"#FFFFFF\")},\n",
    "    'crpss' : {'ssta': dict(cmap='viridis', vmin=0, vmax=.5, eps=0.05),\n",
    "              'ssha': dict(cmap='viridis', vmin=0, vmax=1.0, eps=.1)},\n",
    "}\n",
    "\n",
    "\n",
    "ncols = len(vars)\n",
    "nrows = 1\n",
    "fig = plt.figure(figsize=(ncols*5, nrows*2.5))\n",
    "\n",
    "for i, var in enumerate(vars):\n",
    "    score = verification_per_gridpoint[scorekey][var]\n",
    "    ax = fig.add_subplot(nrows, ncols, i+1, projection=ctp.crs.PlateCarree(central_longitude=180))\n",
    "    im = gpl.plot_map(score.sel(lag=lag), ax=ax, **plparam[scorekey][var], add_bar=False)\n",
    "\n",
    "    ax.set_title(f\"{var}\")\n",
    "        \n",
    "    # Colorbar under each column\n",
    "    axwidth = ax.get_position().width\n",
    "    cbar_ax = fig.add_axes([ 0.5 * axwidth + i * (axwidth*1.3), -0.01, 0.8*axwidth, 0.02])\n",
    "    cb = fig.colorbar(im['im'], cax=cbar_ax, orientation='horizontal', extend='both')\n",
    "    cb.set_label(label=rf\"{scorekey} {vars[i]}\")\n",
    "\n",
    "# Title\n",
    "fig.suptitle(rf\"$\\tau$ = {lag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
